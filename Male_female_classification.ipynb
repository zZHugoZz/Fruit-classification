{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zZHugoZz/Machine-learning-Pytorch/blob/main/Male_female_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Uuo5UJW62zwp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import Callable\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms as T\n",
        "from torchinfo import summary, ModelStatistics\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ipbKrgBLqE-T"
      },
      "outputs": [],
      "source": [
        "SEED = 5432\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4macHp2-vT1s"
      },
      "outputs": [],
      "source": [
        "root_path = Path(\"drive/MyDrive/Machine learning\")\n",
        "datasets_path = root_path.joinpath(\"Datasets/Male and Female face dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "y0LdW2hCvVeD"
      },
      "outputs": [],
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.RandomCrop((224, 224)),\n",
        "    T.ColorJitter(0.5, 0.2, 0.5, 0.3),\n",
        "    T.RandomRotation(25),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5108, 0.4549, 0.4235], [0.2577, 0.2461, 0.2408])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "W1F9PnLqr-nE"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(str(datasets_path), transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4NU6f1NMMDXQ"
      },
      "outputs": [],
      "source": [
        "class FacesDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset: ImageFolder,\n",
        "        train_size: float = 0.8\n",
        "    ) -> None:\n",
        "        self.dataset = dataset\n",
        "        self.train_size = train_size\n",
        "\n",
        "    def __getitem__(self) -> tuple[Dataset, Dataset]:\n",
        "        train_split = int(len(self.dataset) * self.train_size)\n",
        "        test_split = len(self.dataset) - train_split\n",
        "        train_data, test_data = random_split(self.dataset, [train_split, test_split])\n",
        "        return train_data, test_data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_classes(self) -> list[str]:\n",
        "        return self.dataset.classes\n",
        "\n",
        "\n",
        "faces_dataset = FacesDataset(dataset)\n",
        "train_data, test_data = faces_dataset.__getitem__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "UphYFSL3r4XY"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_data, BATCH_SIZE, True, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data, BATCH_SIZE, True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "lIzyyk94ZX-I"
      },
      "outputs": [],
      "source": [
        "def compute_mean_std(\n",
        "    dataloader: DataLoader,\n",
        ") -> tuple[torch.Tensor | float, torch.Tensor | float]:\n",
        "    global_mean = 0.0\n",
        "    global_std = 0.0\n",
        "\n",
        "    for images, _ in dataloader:\n",
        "        mean = 0.0\n",
        "        std = 0.0\n",
        "\n",
        "        for image in images:\n",
        "            mean += image.mean((1, 2))\n",
        "            std += image.std((1, 2))\n",
        "\n",
        "        mean /= len(images)\n",
        "        std /= len(images)\n",
        "\n",
        "        global_mean += mean\n",
        "        global_std += std\n",
        "\n",
        "    global_mean /= len(dataloader)\n",
        "    global_std /= len(dataloader)\n",
        "\n",
        "    return global_mean, global_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cO8IOKGZk8BV"
      },
      "outputs": [],
      "source": [
        "class ModelPerformanceStats:\n",
        "    def __init__(self, epoch_values: list) -> None:\n",
        "        self.epoch_values = epoch_values\n",
        "        self.fig, (self.loss_ax, self.acc_ax) = plt.subplots(1, 2, figsize=(10, 3))\n",
        "\n",
        "    def plot_loss(self, train_loss_values: list, test_loss_values: list) -> None:\n",
        "        self.loss_ax.plot(self.epoch_values, train_loss_values, label=\"train loss\")\n",
        "        self.loss_ax.plot(self.epoch_values, test_loss_values, label=\"test loss\")\n",
        "        self.loss_ax.set_title(\"Loss\")\n",
        "        self.loss_ax.grid()\n",
        "        self.loss_ax.legend(loc=\"upper left\")\n",
        "\n",
        "    def plot_accuracy(self, train_acc_values: list, test_acc_values: list) -> None:\n",
        "        self.acc_ax.plot(self.epoch_values, train_acc_values, label=\"train accuracy\")\n",
        "        self.acc_ax.plot(self.epoch_values, test_acc_values, label=\"test accuracy\")\n",
        "        self.acc_ax.set_title(\"Accuracy\")\n",
        "        self.acc_ax.grid()\n",
        "        self.acc_ax.legend(loc=\"upper left\")\n",
        "\n",
        "    def show(self) -> None:\n",
        "        self.fig.tight_layout()\n",
        "        self.fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "SplKKuoLtk3s"
      },
      "outputs": [],
      "source": [
        "def plot_images(n_rows: int, n_cols: int, datasets_path: Path) -> None:\n",
        "    unormalized_transform = T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "    ])\n",
        "    data = ImageFolder(str(datasets_path), transform=unormalized_transform)\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 10))\n",
        "\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        image, label = data[random.randint(0, len(data))]\n",
        "        ax.imshow(image.permute(1, 2, 0))\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(data.classes[label])\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "NH2E31VGnDGE"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(\n",
        "    n_rows: int, n_cols: int, preds: torch.Tensor, images: torch.Tensor, dataset: ImageFolder\n",
        ") -> None:\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 10))\n",
        "\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        ax.imshow(images[i].permute(1, 2, 0))\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(f\"predicted: {dataset.classes[preds[i]]}\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "2PugUMY6gK0H"
      },
      "outputs": [],
      "source": [
        "def get_summary(model: nn.Module, input_size: tuple[int, ...]) -> ModelStatistics:\n",
        "    return summary(model, input_size)\n",
        "\n",
        "\n",
        "def save_model(model_state_dict: object, path: str, model_file_name: str) -> None:\n",
        "    file = f\"{path}/{model_file_name}\"\n",
        "    torch.save(model_state_dict, file)\n",
        "\n",
        "\n",
        "def validate_model(path: str, model: nn.Module, validation_data: torch.Tensor) -> None:\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.eval()\n",
        "    logits = model(validation_data.to(device))\n",
        "    preds = torch.softmax(logits, dim=1).argmax(dim=1)\n",
        "    preds.cpu()\n",
        "    plot_predictions(4, 4, preds, validation_data, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CmAIgVBypr8"
      },
      "outputs": [],
      "source": [
        "class FaceClassifier(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, hidden_units: int = 10) -> None:\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_features, hidden_units, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_units * 55 * 55, out_features)\n",
        "        )\n",
        "        self.apply(self.weight_init)\n",
        "\n",
        "    def weight_init(self, m: nn.Module) -> None:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_normal_(m.weight, nn.init.calculate_gain(\"relu\"))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "face_classifier = FaceClassifier(3, 2)\n",
        "get_summary(face_classifier, (32, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "pbkCIE5WhhP5"
      },
      "outputs": [],
      "source": [
        "class TrainAndTest:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        train_data: DataLoader,\n",
        "        test_data: DataLoader,\n",
        "        criterion: _Loss,\n",
        "        optimizer: Optimizer,\n",
        "        device: str,\n",
        "        scheduler: ReduceLROnPlateau | None = None\n",
        "    ) -> None:\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self) -> tuple[float, float]:\n",
        "        train_loss = torch.tensor(0, dtype=torch.float32).to(device)\n",
        "        train_acc = torch.tensor(0, dtype=torch.float32).to(device)\n",
        "\n",
        "        self.model.train()\n",
        "        for X, y in self.train_data:\n",
        "            X, y = X.to(self.device), y.to(self.device)\n",
        "            preds = self.model(X)\n",
        "\n",
        "            loss = self.criterion(preds, y)\n",
        "            acc = self.get_accuracy(torch.softmax(preds, dim=1).argmax(dim=1), y)\n",
        "            train_loss += loss\n",
        "            train_acc += acc\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        if self.scheduler is not None:\n",
        "            self.scheduler.step(train_loss)\n",
        "\n",
        "        train_loss /= len(self.train_data)\n",
        "        train_acc /= len(self.train_data)\n",
        "        print(f\"train loss: {train_loss:.5f} | train accuracy: {train_acc:.2f}%\")\n",
        "        return train_loss.item(), train_acc.item()\n",
        "\n",
        "    def test_step(self) -> tuple[float, float]:\n",
        "        test_loss = torch.tensor(0, dtype=torch.float32).to(device)\n",
        "        test_acc = torch.tensor(0, dtype=torch.float32).to(device)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.inference_mode():\n",
        "            for X, y in self.test_data:\n",
        "                X, y = X.to(self.device), y.to(self.device)\n",
        "                preds = self.model(X)\n",
        "\n",
        "                loss = self.criterion(preds, y)\n",
        "                acc = self.get_accuracy(torch.softmax(preds, dim=1).argmax(dim=1), y)\n",
        "                test_loss += loss\n",
        "                test_acc += acc\n",
        "\n",
        "            test_loss /= len(self.test_data)\n",
        "            test_acc /= len(self.test_data)\n",
        "            print(f\"test loss: {test_loss:.5f} | test accuracy: {test_acc:.2f}%\\n\")\n",
        "            return test_loss.item(), test_acc.item()\n",
        "\n",
        "    def get_accuracy(self, preds: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "        equals = torch.eq(preds, labels).sum().item()\n",
        "        acc = (equals / len(labels)) * 100\n",
        "        return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi3p2o3Tketm"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(face_classifier.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)\n",
        "\n",
        "epoch_values = []\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "train_acc_values = []\n",
        "test_acc_values = []\n",
        "\n",
        "train_test = TrainAndTest(\n",
        "    face_classifier,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        ")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"EPOCH {epoch}\\n----------\")\n",
        "    train_loss, train_acc = train_test.train_step()\n",
        "    test_loss, test_acc = train_test.test_step()\n",
        "\n",
        "    epoch_values.append(epoch)\n",
        "    train_loss_values.append(train_loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    train_acc_values.append(train_acc)\n",
        "    test_acc_values.append(test_acc)\n",
        "\n",
        "save_model(\n",
        "    face_classifier.state_dict(),\n",
        "    \"drive/MyDrive/Machine learning/Models\",\n",
        "    \"face_classifier\"\n",
        ")\n",
        "\n",
        "plot_performances = ModelPerformanceStats(epoch_values)\n",
        "plot_performances.plot_loss(train_loss_values, test_loss_values)\n",
        "plot_performances.plot_accuracy(train_acc_values, test_acc_values)\n",
        "plot_performances.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_image\n",
        "\n",
        "\n",
        "test_path = Path(\"/content/drive/MyDrive/Machine learning/Datasets/Male and Female face dataset/Test images\")\n",
        "test_transforms = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "images = [\n",
        "    test_transforms(read_image(str(image_path)))\n",
        "    for image_path in test_path.glob(\"*\")\n",
        "    if image_path.suffix.lower() in [\".jpeg\", \".jpg\", \".png\"]\n",
        "]\n",
        "images = [image for image in images if image.shape != torch.Size((4, 224, 224))]\n",
        "images = torch.stack(images)"
      ],
      "metadata": {
        "id": "sZwdPt9vPjpL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Machine learning/Models/face_classifier\"\n",
        "\n",
        "loaded_model = face_classifier\n",
        "loaded_model.load_state_dict(torch.load(model_path, torch.device(device)))\n",
        "logits = loaded_model(images)\n",
        "preds = torch.softmax(logits, dim=1).argmax(dim=1)\n",
        "\n",
        "plot_predictions(2, 4, preds, images, dataset)"
      ],
      "metadata": {
        "id": "E6BvKaImABk2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PuVymteU0aSzPp0ilDHUv0KJ99z3cu4l",
      "authorship_tag": "ABX9TyN6kM73UqOTTJ/oj404zUnJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}